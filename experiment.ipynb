{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # required for relative imports in jupyter lab\n",
    "sys.path.insert(0, '../') \n",
    "\n",
    "from cosmosis.model import FFNet\n",
    "from dataset import Dummy, QM7, QM7b, QM7X, QM9, ANI1x\n",
    "from learning import Learn, Selector\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'D_in': 128, \n",
    "                'H': 512, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "ds_params = {'make': 'make_regression',\n",
    "             'make_params': {'n_samples': 10000,\n",
    "                             'n_features': 128}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.1,.8)}\n",
    "sched_params = {'factor': .1,\n",
    "                'patience': 10}\n",
    "l = Learn(Dummy, FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False,\n",
    "          batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'D_in': 23*23, \n",
    "                'H': 4096, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "ds_params = {}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.1,.8)}\n",
    "sched_params = {'factor': .1,\n",
    "                'patience': 10,\n",
    "                'cooldown': 10}\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn(QM7, FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False, \n",
    "          batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'D_in': 23*23+13, \n",
    "                'H': 4096, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "ds_params = {'target': 'E', \n",
    "             'features': ['alpha_p','alpha_s','HOMO_g','HOMO_p','HOMO_z','LUMO_g',\n",
    "                          'LUMO_p','LUMO_z','IP','EA','E1','Emax','Imax']}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.1,.8)}\n",
    "sched_params = {'factor': .1,\n",
    "                'patience': 10,\n",
    "                'cooldown': 10}\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn(QM7b, FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False, \n",
    "          batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'D_in': 12*12, # nxn coulomb matrix\n",
    "                'H': 2048, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "ds_params = {'n': 133885, \n",
    "             'features': ['coulomb'], \n",
    "             'target': 'U0',\n",
    "             'pad': 12, \n",
    "             'filter_on': ('n_atoms','>','12'),\n",
    "             'use_pickle': True}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.1,.8)}\n",
    "sched_params = {'factor': .1,\n",
    "                'patience': 10,\n",
    "                'cooldown': 10}\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn(QM9, FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False, \n",
    "          batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'D_in': 32*63+63+63+63, \n",
    "                'H': 8192, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel',\n",
    "                'padding_idx': 0}\n",
    "\n",
    "ds_params = {'features': ['atomic_numbers','coordinates'],\n",
    "             'targets': ['wb97x_dz.energy'],\n",
    "             'embed': [(6,32,False)],\n",
    "             'pad': 63, #length of the longest molecule in the dataset\n",
    "             'criterion': None,\n",
    "             'conformation': 'random',\n",
    "             'in_file': './data/ani1x/ani1x-release.h5'}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.1,.8)}\n",
    "sched_params = {'factor': .1,\n",
    "                'patience': 10,\n",
    "                'cooldown': 10}\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn(ANI1x, FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False, \n",
    "          batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping...  <HDF5 file \"1000.hdf5\" (mode r)>\n",
      "mapping...  <HDF5 file \"2000.hdf5\" (mode r)>\n",
      "mapping...  <HDF5 file \"3000.hdf5\" (mode r)>\n",
      "mapping...  <HDF5 file \"4000.hdf5\" (mode r)>\n",
      "mapping...  <HDF5 file \"5000.hdf5\" (mode r)>\n",
      "mapping...  <HDF5 file \"6000.hdf5\" (mode r)>\n",
      "mapping...  <HDF5 file \"7000.hdf5\" (mode r)>\n",
      "mapping...  <HDF5 file \"8000.hdf5\" (mode r)>\n",
      "molecular formula (idmol) mapped:  6899\n",
      "total molecular structures (idconf) mapped:  6899\n",
      "<class 'dataset.QM7X'> dataset created...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fltr/qchem/dataset.py\", line 636, in __getitem__\n    idx.append(QM7X.atomic_n[atom])\nKeyError: 17\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-22fe574a8473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mopt_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msched_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msched_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0madapt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_embed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m           batch_size=128, epochs=2)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#find the longest molecule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cosmosis/learning.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, Dataset, Model, Sampler, Optimizer, Scheduler, Criterion, ds_params, model_params, sample_params, opt_params, sched_params, crit_params, adapt, load_model, load_embed, save_model, batch_size, epochs)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_train_val_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cosmosis/learning.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_con\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mx_con\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_con\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/fltr/qchem/dataset.py\", line 636, in __getitem__\n    idx.append(QM7X.atomic_n[atom])\nKeyError: 17\n"
     ]
    }
   ],
   "source": [
    "ds_params = {'features': ['atNUM','atXYZ'],\n",
    "             'pad': 23,\n",
    "             'targets': ['eAT'],\n",
    "             'embed': [(9,16,True)],\n",
    "             'selector': ['i1-c1-opt'],\n",
    "             'use_h5': False}\n",
    "\n",
    "model_params = {'D_in': 23*16+23*3, \n",
    "                'H': 2048, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel',\n",
    "                'padding_idx': 0}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.1,.8)}\n",
    "sched_params = {'factor': .1,\n",
    "                'patience': 10,\n",
    "                'cooldown': 10}\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn(QM7X, FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False, \n",
    "          batch_size=128, epochs=2)\n",
    "\n",
    "#find the longest molecule\n",
    "#qm7x = QM7X(**ds_params)\n",
    "#l = 0\n",
    "#for i in qm7x.ds_idx:\n",
    "#    s = qm7x[i][0].shape.numel()\n",
    "#    if s > l:\n",
    "#        l = s\n",
    "#print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the longest molecule\n",
    "ds_params = {'features': ['atNUM','atXYZ'],\n",
    "             'pad': 23,\n",
    "             'targets': ['eAT'],\n",
    "             'embed': [(7,16,True)],\n",
    "             'selector': ['i1-c1-opt'],\n",
    "             'use_h5': False}\n",
    "\n",
    "qm7x = QM7X(**ds_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm7x.ds_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm7x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
