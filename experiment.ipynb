{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples demonstrating the use of the icanswim/qchem repo \n",
    "## for quantum mechanic geometric machine learning utilizing pytorch, pyg and rdkit.\n",
    "## This is a demonstration of the use of the icanswim/cosmosis repo for \n",
    "## data science and machine learning projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys # required for relative imports in jupyter lab\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning,\n",
    "                            message='TypedStorage is deprecated')\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from cosmosis.model import FFNet\n",
    "from cosmosis.dataset import SKDS, Pad, Flatten, Reshape, SqueezeN, Index\n",
    "\n",
    "from learning import Learn, Selector\n",
    "from dataset import QM7, QM7b, QM7X, ANI1x, QM9, PGDS\n",
    "from model import GraphNet, PygModel, EncoderLoss, GraphNetVariationalEncoder \n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, L1Loss, NLLLoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example exploring cosmosis/qchem QM9 dataset \n",
    "#use the qchem rdkit branch for rdkit data augmentation\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['atomic_number','mulliken'],\n",
    "                                                             'coulomb': ['coulomb'],\n",
    "                                                            },\n",
    "                                             'criterion_input': {'target': ['U0']}},\n",
    "                              'n': 1000, #non-random subset for testing,\n",
    "                              'use_pickle': False}}\n",
    "\n",
    "qm9 = QM9(**ds_params['train_params'])\n",
    "qm9[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example exploring cosmosis/qchem QM9 dataset\n",
    "\n",
    "l, s, li, si = 0, 9999, 0, 0\n",
    "for i in qm9.ds_idx:\n",
    "    d = qm9[i]['model_input']['X'].shape[0]\n",
    "    if d > l:\n",
    "        l = d\n",
    "        li = i\n",
    "    if d < s:\n",
    "        s = d\n",
    "        si = i\n",
    "print('longest molecule index: ', li, ' length: ', l)\n",
    "print('shortest molecule index: ', si, ' length: ', s)\n",
    "qm9[si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example exploring cosmosis/qchem PyG dataset wrapper with Data object output\n",
    "\n",
    "import copy\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        # Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': IndexY(1)}}}\n",
    "\n",
    "pgds = PGDS(**ds_params['train_params'])\n",
    "ds_idx = np.arange(1000)\n",
    "selector = Selector(train_idx=ds_idx)\n",
    "selector('train')\n",
    "loader = DataLoader(pgds, batch_size=2, sampler=selector)\n",
    "batch = next(iter(loader))\n",
    "print('batch: ', batch)\n",
    "print('batch.ptr: ', batch.ptr)\n",
    "print('batch.idx: ', batch.idx)\n",
    "print('batch.x: ', batch.x)\n",
    "print('pgds[1]: ', pgds[1])\n",
    "print('pgds[1].x: ', pgds[1].x)\n",
    "print('pgds[1].y: ', pgds[1].y)\n",
    "print('pgds[1].idx: ', pgds[1].idx)\n",
    "print('pgds[1].edge_index: ', pgds[1].edge_index)\n",
    "print('pgds[1].edge_attr: ', pgds[1].edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem QM9 dataset with filter\n",
    "#use the qchem rdkit branch for rdkit data augmentation\n",
    "\n",
    "qm9_features = ['A','B','C','mu','alpha','homo','lumo', 'gap','r2','zpve',\n",
    "                'U0','U','H','G','Cv','qm9_n_atoms','qm9_block','qm9_atom_type',\n",
    "                'qm9_xyz','mulliken','in_file','smile','distance','coulomb']\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['U0']}},\n",
    "                              'n': 10000, #non-random subset for testing\n",
    "                              'transforms': {'coulomb': [Pad((29,29)),Reshape((-1))],\n",
    "                                             'U0': [SqueezeN()]},\n",
    "                              'filter_on': ('n_atoms','>','10'), #filter out molecules with less than 10 atoms\n",
    "                              'use_pickle': False}}\n",
    "\n",
    "model_params = {'in_channels': 29*29, \n",
    "                'hidden': 4096, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'\n",
    "               }\n",
    "                \n",
    "metrics_params = {'report_interval': 1,\n",
    "                  'log_plot': False}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM9], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          squeeze_y_pred=True, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with Data object output with\n",
    "#custom transforms and sklearn metrics and custom PyG model\n",
    "\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        #Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "model_params = {'in_channels': 11, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 1,\n",
    "                'depth': 1,\n",
    "                'convolution': 'NetConv',\n",
    "                'pool': 'MeanAggregation',\n",
    "                'dropout': .1,\n",
    "                'softmax': None,\n",
    "                'activation': 'relu',\n",
    "                'edge_features': 4,\n",
    "               }\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': T.Compose([IndexY(0), \n",
    "                                                                   ])}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], GraphNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=True, batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating pytorch geometric QM9 dataset...\n",
      "CDataset created...\n",
      "FFNet model loaded...\n",
      "CModel loaded...\n",
      "GraphNet <module 'torch_geometric.nn.conv' from '/home/operat0r/miniconda3/envs/qchem/lib/python3.10/site-packages/torch_geometric/nn/conv/__init__.py'> loaded...\n",
      "CModel loaded...\n",
      "FFNet model loaded...\n",
      "CModel loaded...\n",
      "FFNet model loaded...\n",
      "CModel loaded...\n",
      "GraphNetVariationalEncoder loaded...\n",
      "CModel loaded...\n",
      "running model on gpu...\n",
      "learning time: 0:00:09.787214\n",
      "epoch: 0, lr: 0.01\n",
      "train loss: 65747.88821384936, val loss: 0.021237395082910854\n",
      "sklearn train metric: 0.5029423249633882, sklearn validation metric: 0.5255567958418719\n",
      "learning time: 0:00:26.089650\n",
      "epoch: 2, lr: 0.01\n",
      "train loss: 0.011076859211627866, val loss: 0.02148923712472121\n",
      "sklearn train metric: 0.568190600097552, sklearn validation metric: 0.5256993057588562\n",
      "learning time: 0:00:42.116375\n",
      "epoch: 4, lr: 0.005\n",
      "train loss: 0.010836240402619603, val loss: 0.021251138051350912\n",
      "sklearn train metric: 0.6040956502649579, sklearn validation metric: 0.5350813426573426\n",
      "learning time: 0:00:58.559172\n",
      "epoch: 6, lr: 0.005\n",
      "train loss: 0.010778192483203513, val loss: 0.021409190197785696\n",
      "sklearn train metric: 0.6133607469260035, sklearn validation metric: 0.5391679652073973\n",
      "learning time: 0:01:14.928424\n",
      "epoch: 8, lr: 0.005\n",
      "train loss: 0.010748259421490448, val loss: 0.021560952564080558\n",
      "sklearn train metric: 0.6152004851545065, sklearn validation metric: 0.5380550052843652\n",
      "learning time: 0:01:31.181029\n",
      "epoch: 10, lr: 0.005\n",
      "train loss: 0.010735221049735243, val loss: 0.021368676920731862\n",
      "sklearn train metric: 0.6182426230466459, sklearn validation metric: 0.5387011531249309\n",
      "learning time: 0:01:47.660775\n",
      "epoch: 12, lr: 0.005\n",
      "train loss: 0.010715583326216315, val loss: 0.02136888951063156\n",
      "sklearn train metric: 0.6200355364723047, sklearn validation metric: 0.5419516346770418\n",
      "learning time: 0:02:04.021405\n",
      "epoch: 14, lr: 0.005\n",
      "train loss: 0.010699683734753601, val loss: 0.021242470170060795\n",
      "sklearn train metric: 0.6223974106051395, sklearn validation metric: 0.5365388304757741\n",
      "learning time: 0:02:20.330139\n",
      "epoch: 16, lr: 0.005\n",
      "train loss: 0.010706490154942157, val loss: 0.021220721304416656\n",
      "sklearn train metric: 0.6220082847869406, sklearn validation metric: 0.5422159587454668\n",
      "learning time: 0:02:36.878313\n",
      "epoch: 18, lr: 0.005\n",
      "train loss: 0.01068546704318322, val loss: 0.02111895109216372\n",
      "sklearn train metric: 0.6251468388578756, sklearn validation metric: 0.5428313077427279\n",
      "learning time: 0:02:53.168443\n",
      "epoch: 20, lr: 0.005\n",
      "train loss: 0.010676980753180007, val loss: 0.020956990619500477\n",
      "sklearn train metric: 0.6253671204044254, sklearn validation metric: 0.5404679649808394\n",
      "learning time: 0:03:09.743028\n",
      "epoch: 22, lr: 0.005\n",
      "train loss: 0.010659655647903261, val loss: 0.020691736166675887\n",
      "sklearn train metric: 0.6292925300770891, sklearn validation metric: 0.5422328033367456\n",
      "learning time: 0:03:26.588741\n",
      "epoch: 24, lr: 0.005\n",
      "train loss: 0.010656641114135864, val loss: 0.020747061694661777\n",
      "sklearn train metric: 0.6289494305121167, sklearn validation metric: 0.5425284725484499\n"
     ]
    }
   ],
   "source": [
    "#example graph variational autoencoder with adversarially regulation and GCNConv encoder\n",
    "\n",
    "model_params = {'in_channels': 11, \n",
    "                'hidden': 32, \n",
    "                'out_channels': 32,\n",
    "                'depth': 2,\n",
    "                'softmax': None,\n",
    "                'pool': None,\n",
    "                'convolution': 'GCNConv'}\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': None}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False,\n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'adversarial': False,\n",
    "               'disc_params': {'in_channels': 32, 'hidden': 64, \n",
    "                                'out_channels': 32, 'softmax': None}}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15),\n",
    "                 'subset': False}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], GraphNetVariationalEncoder, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=EncoderLoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=False, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with Data object output with\n",
    "#custom transforms and sklearn metrics and custom PyG model\n",
    "\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        # Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "model_params = {'in_channels': 11, \n",
    "                'hidden': 256, \n",
    "                'out_channels': 1,\n",
    "                'depth': 2,\n",
    "                'convolution': 'SAGEConv',\n",
    "                'pool': 'MeanAggregation',\n",
    "                'dropout': .1,\n",
    "                'softmax': None,\n",
    "                'activation': 'relu',\n",
    "               }\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': T.Compose([IndexY(0), \n",
    "                                                                   ])}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], GraphNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=True, batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with Data object output with\n",
    "#custom transforms and sklearn metrics and PyG model\n",
    "\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        # Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "model_params = {'model_name': 'GraphSAGE',\n",
    "                'softmax': None,\n",
    "                'pool': 'MeanAggregation',\n",
    "                'ffnet': True,\n",
    "                'in_channels': 256, #ffnet params\n",
    "                'hidden': 256, \n",
    "                'out_channels': 1, \n",
    "                'pyg_params': {'in_channels': 11, #GraphSAGE params\n",
    "                               'hidden_channels': 256,\n",
    "                               'num_layers': 2,\n",
    "                               'out_channels': 256,\n",
    "                               'dropout': .1,\n",
    "                               'norm': 'BatchNorm'}}\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': T.Compose([IndexY(0)])}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], PygModel, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=True, batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with custum transform with\n",
    "#dictionary output and custom cosmosis model\n",
    "\n",
    "model_params = {'in_channels': 319, \n",
    "                'hidden': 512, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {'y': [Index(0)],\n",
    "                                             'x': [Pad((29,11)), Flatten()]},\n",
    "                              'input_dict': {'model_input': {'X': ['x']},\n",
    "                                             'criterion_input': {'target': ['y']}},\n",
    "                              'pg_params': {'root': './data/'}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using cosmosis/qchem QM7 dataset and custom cosmosis model\n",
    "model_params = {'in_channels': 23*23, \n",
    "                'hidden': 2048, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['ae']}},\n",
    "                              'in_file': './data/qm7/qm7.mat',\n",
    "                              'transforms': {'coulomb': [Flatten()]}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM7], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using the cosmosis/qchem QM7b dataset and custom cosmosis model\n",
    "model_params = {'in_channels': 23*23, \n",
    "                'hidden': 2048, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['E']}},\n",
    "                              'in_file': './data/qm7b/qm7b.mat',\n",
    "                              'transforms': {'coulomb': [Flatten()]}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM7b], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params, \n",
    "          batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example exploring cosmosis/qchem QM7X dataset\n",
    "\n",
    "features = ['DIP','HLgap','atC6','atNUM','atPOL','atXYZ','eAT','hDIP',\n",
    "            'eC','eDFTB+MBD','eEE','eH','eKIN','eKSE','eL','eMBD','eNE', \n",
    "            'eNN','ePBE0','ePBE0+MBD','eTS','eX','eXC','eXX','hCHG', \n",
    "            'hRAT','hVDIP','hVOL','mC6','mPOL','mTPOL','pbe0FOR', \n",
    "            'sMIT','sRMSD','totFOR','vDIP','vEQ','vIQ','vTQ','vdwFOR','vdwR',\n",
    "            'coulomb'] #(1110,) with pad=23\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['atNUM']},\n",
    "                                             'criterion_input': {'target': ['eAT']}},\n",
    "                              'transforms': {},\n",
    "                              'n': 1000, #non-random subset for testing\n",
    "                              'selector': ['opt']}}\n",
    "\n",
    "qm7x = QM7X(**ds_params['train_params'])\n",
    "\n",
    "l, m = 0, 0\n",
    "for i in qm7x.ds_idx:\n",
    "    s = qm7x[i]['model_input']['X'].shape[0]\n",
    "    if s > l:\n",
    "        l = s\n",
    "        m = i\n",
    "print('longest molecule length: ', l, ' index: ', m)\n",
    "print(qm7x[m]['model_input']['X'].shape) \n",
    "qm7x[m]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using the cosmosis/qchem QM7X dataset with filter and custom cosmosis model\n",
    "model_params = {'in_channels': 23*23,\n",
    "                'hidden': 2048, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "features = ['DIP','HLgap','atC6','atNUM','atPOL','atXYZ','hDIP','eAT',\n",
    "            'eC','eDFTB+MBD','eEE','eH','eKIN','eKSE','eL','eMBD','eNE', \n",
    "            'eNN','ePBE0','ePBE0+MBD','eTS','eX','eXC','eXX','hCHG', \n",
    "            'hRAT','hVDIP','hVOL','mC6','mPOL','mTPOL','pbe0FOR', \n",
    "            'sMIT','sRMSD','totFOR','vDIP','vEQ','vIQ','vTQ','vdwFOR','vdwR',\n",
    "            'coulomb','distance']\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['eAT']}},\n",
    "                              'transforms': {'coulomb': [Pad((23,23)), Flatten()]},\n",
    "                              'selector': ['opt'],\n",
    "                              'n': 1000, #non-random subset for testing\n",
    "                             }}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15),\n",
    "                 #'subset': .2 #create random subset\n",
    "                } \n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM7X], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using cosmosis/qchem ANI1x dataset with filter and custom cosmosis model\n",
    "\n",
    "model_params = {'in_channels': 63*63, #length of the longest molecule in the dataset\n",
    "                'hidden': 2000, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'\n",
    "               }\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['wb97x_dz.energy']}},\n",
    "                              'transforms': {'coulomb': [Pad((63,63)), Flatten()]},\n",
    "                              'criterion': ['wb97x_dz.energy'],\n",
    "                              'conformation': 'max',\n",
    "                              'in_file': './data/ani1x/ani1x-release.h5'}}\n",
    "\n",
    "metrics_params = {'report_interval': 20}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([ANI1x], FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
