{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples demonstrating the use of the icanswim/qchem repo \n",
    "## for quantum mechanic geometric machine learning utilizing pytorch, pyg and rdkit.\n",
    "## This is a demonstration of the use of the icanswim/cosmosis repo for \n",
    "## data science and machine learning projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys # required for relative imports in jupyter lab\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning,\n",
    "                            message='TypedStorage is deprecated')\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from cosmosis.model import FFNet\n",
    "from cosmosis.dataset import SKDS, Pad1d, Flatten, Reshape, SqueezeN, Index, EmbedLookup\n",
    "\n",
    "from learning import Learn, Selector\n",
    "from dataset import QM7, QM7b, QM7X, ANI1x, QM9, PGDS\n",
    "from model import GraphNet, PygModel, EncoderLoss, GraphNetVariationalEncoder \n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, L1Loss, NLLLoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating QM9 dataset...\n",
      "molecules scanned:  1\n",
      "molecules created:  1\n",
      "total molecules scanned:  100\n",
      "total uncharacterized molecules removed:  3\n",
      "total molecules created:  97\n",
      "CDataset created...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_input': {'X': array([6., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       "  'coulomb': array([36.85811234, 36.85811234, 36.85811234, 10.35029206, 10.59475792,\n",
       "         10.70230408, 10.84096245, 10.47478299, 10.79368986, 10.55102735,\n",
       "         10.794133  , 10.58947445, 10.73455259, 10.64062065, 10.54992908,\n",
       "          0.90316671,  0.90380116,  0.906592  ,  0.5       ,  0.5       ,\n",
       "          0.5       ,  1.80682708,  1.74579716,  1.79894831,  1.75850456,\n",
       "          1.79902217,  1.76491241,  1.7890921 ,  1.77343678,  1.75832151,\n",
       "          0.90316671,  0.90380116,  0.906592  ,  1.72504868,  1.76579299,\n",
       "          1.78371735,  0.5       ,  0.5       ,  0.5       ,  1.75850456,\n",
       "          1.79902217,  1.76491241,  1.7890921 ,  1.77343678,  1.75832151,\n",
       "          0.90316671,  0.90380116,  0.906592  ,  1.72504868,  1.76579299,\n",
       "          1.78371735,  1.80682708,  1.74579716,  1.79894831,  0.5       ,\n",
       "          0.5       ,  0.5       ,  1.7890921 ,  1.77343678,  1.75832151,\n",
       "          0.90316671,  0.90380116,  0.906592  ,  1.72504868,  1.76579299,\n",
       "          1.78371735,  1.80682708,  1.74579716,  1.79894831,  1.75850456,\n",
       "          1.79902217,  1.76491241,  0.5       ,  0.5       ,  0.5       ])},\n",
       " 'criterion_input': {'target': array([-40.47893], dtype=float32)}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example exploring cosmosis/qchem QM9 dataset \n",
    "#use the qchem rdkit branch for rdkit data augmentation\n",
    "\n",
    "qm9_features = ['A','B','C','mu','alpha','homo','lumo', 'gap','r2','zpve',\n",
    "                'U0','U','H','G','Cv','qm9_n_atoms','qm9_block','qm9_atom_type',\n",
    "                'qm9_xyz','mulliken','in_file','smile','distance','coulomb']\n",
    "\n",
    "rdkit_features = ['atom_type','atomic_number','aromatic','chirality',\n",
    "                  'degree','charge','n_hs','n_rads','hybridization',\n",
    "                  'edge_indices','edge_attr','rdmol_block','n_atoms',\n",
    "                  'xyz','distance','coulomb','adjacency','rdmol']\n",
    "\n",
    "rdkit_edge = ['edge_indices','edge_attr']\n",
    "\n",
    "lookup_hybrid = QM9.embed_lookup['hybridization']\n",
    "lookup_chiral = QM9.embed_lookup['chirality']\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': [\n",
    "                                                                   'atomic_number',\n",
    "                                                                   #'aromatic',\n",
    "                                                                   #'degree',\n",
    "                                                                  ],\n",
    "                                                             #'edge_idx': ['edge_indices'],\n",
    "                                                             #'edge_attr': ['edge_attr'],\n",
    "                                                             'coulomb': ['coulomb'],\n",
    "                                                             #'distance': ['distance'],\n",
    "                                                             #'embed': ['hybridization'],\n",
    "                                                             #'adjacency': ['adjacency'],\n",
    "                                                            },\n",
    "                                             'criterion_input': {'target': ['U0']}},\n",
    "                              'transforms': {\n",
    "                                             #'hybridization': [Pad1d(29), EmbedLookup(lookup_hybrid)],\n",
    "                                             #'chirality': [Pad1d(29), EmbedLookup(lookup_chiral)],\n",
    "                                             'atomic_number': [Pad1d(29)],\n",
    "                                             #'arommatic': [Pad1d(29)],\n",
    "                                             #'degree': [Pad1d(29)],\n",
    "                                             #'mulliken': [Pad1d(29)],\n",
    "                                             'coulomb': [Reshape((-1))],\n",
    "                                            },\n",
    "                              #'filter_on': ('n_atoms','<','10'), \n",
    "                              'n': 100, #non-random subset for testing,\n",
    "                              'use_pickle': False,\n",
    "                              'n_conformers': 3}}\n",
    "\n",
    "qm9 = QM9(**ds_params['train_params'])\n",
    "qm9[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qm9[1]['model_input']['coulomb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coul = qm9[1]['model_input']['coulomb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coul = coul.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating QM9 dataset...\n",
      "molecules scanned:  1\n",
      "molecules created:  1\n",
      "total molecules scanned:  1017\n",
      "total uncharacterized molecules removed:  26\n",
      "total molecules created:  974\n",
      "CDataset created...\n",
      "FFNet model loaded...\n",
      "CModel loaded...\n",
      "running model on gpu...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 129, in collate\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 129, in collate\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 183, in collate_numpy_array_fn\n    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [12, 12] at entry 0 and [9, 9] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 67\u001b[0m\n\u001b[1;32m     59\u001b[0m sched_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m.5\u001b[39m,\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     61\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooldown\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     62\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_lr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m.005\u001b[39m}\n\u001b[1;32m     64\u001b[0m opt_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.01\u001b[39m}\n\u001b[0;32m---> 67\u001b[0m l \u001b[38;5;241m=\u001b[39m Learn([QM9], FFNet, Selector, \n\u001b[1;32m     68\u001b[0m           Optimizer\u001b[38;5;241m=\u001b[39mAdam, Scheduler\u001b[38;5;241m=\u001b[39mReduceLROnPlateau, Criterion\u001b[38;5;241m=\u001b[39mL1Loss,\n\u001b[1;32m     69\u001b[0m           model_params\u001b[38;5;241m=\u001b[39mmodel_params, ds_params\u001b[38;5;241m=\u001b[39mds_params, sample_params\u001b[38;5;241m=\u001b[39msample_params,\n\u001b[1;32m     70\u001b[0m           opt_params\u001b[38;5;241m=\u001b[39mopt_params, sched_params\u001b[38;5;241m=\u001b[39msched_params, crit_params\u001b[38;5;241m=\u001b[39mcrit_params,\n\u001b[1;32m     71\u001b[0m           squeeze_y_pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/qchem/learning.py:301\u001b[0m, in \u001b[0;36mLearn.__init__\u001b[0;34m(self, Datasets, Model, Sampler, Metrics, DataLoader, Optimizer, Scheduler, Criterion, ds_params, model_params, sample_params, opt_params, sched_params, crit_params, metrics_params, adapt, load_model, load_embed, save_model, batch_size, epochs, squeeze_y_pred, gpu, target)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mshuffle_train_val_idx()\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m no_grad():\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/qchem/learning.py:354\u001b[0m, in \u001b[0;36mLearn.run\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    347\u001b[0m     drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    349\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbs, \n\u001b[1;32m    350\u001b[0m                              sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler(flag\u001b[38;5;241m=\u001b[39mflag), \n\u001b[1;32m    351\u001b[0m                              num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    352\u001b[0m                              drop_last\u001b[38;5;241m=\u001b[39mdrop_last)\n\u001b[0;32m--> 354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    355\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbs\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu: \n",
      "File \u001b[0;32m~/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 129, in collate\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 129, in collate\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 183, in collate_numpy_array_fn\n    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fltr/miniconda3/envs/qchem/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [12, 12] at entry 0 and [9, 9] at entry 1\n"
     ]
    }
   ],
   "source": [
    "#example cosmosis/qchem QM9 dataset with filter\n",
    "#use the qchem rdkit branch for rdkit data augmentation\n",
    "\n",
    "qm9_features = ['A','B','C','mu','alpha','homo','lumo', 'gap','r2','zpve',\n",
    "                'U0','U','H','G','Cv','qm9_n_atoms','qm9_block','qm9_atom_type',\n",
    "                'qm9_xyz','mulliken','in_file','smile','distance','coulomb']\n",
    "\n",
    "rdkit_features = ['atom_type','atomic_number','aromatic','chirality',\n",
    "                  'degree','charge','n_hs','n_rads','hybridization',\n",
    "                  'edge_indices','edge_attr','rdmol_block','n_atoms',\n",
    "                  'xyz','distance','coulomb','adjacency','rdmol']\n",
    "\n",
    "rdkit_edge = ['edge_indices','edge_attr']\n",
    "\n",
    "lookup_hybrid = QM9.embed_lookup['hybridization']\n",
    "lookup_chiral = QM9.embed_lookup['chirality']\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': [\n",
    "                                                                   'atomic_number',\n",
    "                                                                   #'aromatic',\n",
    "                                                                   'degree',\n",
    "                                                                  ],\n",
    "                                                             #'edge_idx': ['edge_indices'],\n",
    "                                                             #'edge_attr': ['edge_attr'],\n",
    "                                                             'coulomb': ['coulomb'],\n",
    "                                                             #'distance': ['distance'],\n",
    "                                                             #'embed': ['hybridization'],\n",
    "                                                             #'adjacency': ['adjacency'],\n",
    "                                                            },\n",
    "                                             'criterion_input': {'target': ['U0']}},\n",
    "                              'transforms': {'hybridization': [Pad((29,)), EmbedLookup(lookup_hybrid)],\n",
    "                                             'chirality': [Pad((29,)), EmbedLookup(lookup_chiral)],\n",
    "                                             'atomic_number': [Pad((29,))],\n",
    "                                             'arommatic': [Pad((29,))],\n",
    "                                             'degree': [Pad((29,))],\n",
    "                                             'mulliken': [Pad((29,))]\n",
    "                                             'coulomb': [Pad((29,29))],\n",
    "                                            },\n",
    "                              #'filter_on': ('n_atoms','<','10'), \n",
    "                              'n': 1000, #non-random subset for testing,\n",
    "                              'use_pickle': False,\n",
    "                              'n_conformers': 10}}\n",
    "\n",
    "model_params = {'in_channels': 29+29, \n",
    "                'hidden': 2048, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel',\n",
    "                #'embed_params': [('hybridization',9,8,0,True)],\n",
    "               }      \n",
    "\n",
    "metrics_params = {'report_interval': 1,\n",
    "                  'log_plot': False}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15),\n",
    "                 #'subset': .2, #create random subset\n",
    "                }\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "\n",
    "l = Learn([QM9], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          squeeze_y_pred=False, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example exploring cosmosis/qchem QM9 dataset\n",
    "\n",
    "l, s, li, si = 0, 9999, 0, 0\n",
    "for i in qm9.ds_idx:\n",
    "    d = qm9[i]['model_input']['X'].shape[0]\n",
    "    if d > l:\n",
    "        l = d\n",
    "        li = i\n",
    "    if d < s:\n",
    "        s = d\n",
    "        si = i\n",
    "print('longest molecule index: ', li, ' length: ', l)\n",
    "print('shortest molecule index: ', si, ' length: ', s)\n",
    "qm9[si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example exploring cosmosis/qchem PyG dataset wrapper with Data object output\n",
    "\n",
    "import copy\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        # Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': IndexY(1)}}}\n",
    "\n",
    "pgds = PGDS(**ds_params['train_params'])\n",
    "ds_idx = np.arange(1000)\n",
    "selector = Selector(train_idx=ds_idx)\n",
    "selector('train')\n",
    "loader = DataLoader(pgds, batch_size=2, sampler=selector)\n",
    "batch = next(iter(loader))\n",
    "print('batch: ', batch)\n",
    "print('batch.ptr: ', batch.ptr)\n",
    "print('batch.idx: ', batch.idx)\n",
    "print('batch.x: ', batch.x)\n",
    "print('pgds[1]: ', pgds[1])\n",
    "print('pgds[1].x: ', pgds[1].x)\n",
    "print('pgds[1].y: ', pgds[1].y)\n",
    "print('pgds[1].idx: ', pgds[1].idx)\n",
    "print('pgds[1].edge_index: ', pgds[1].edge_index)\n",
    "print('pgds[1].edge_attr: ', pgds[1].edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem QM9 dataset with filter\n",
    "#use the qchem rdkit branch for rdkit data augmentation\n",
    "\n",
    "qm9_features = ['A','B','C','mu','alpha','homo','lumo', 'gap','r2','zpve',\n",
    "                'U0','U','H','G','Cv','qm9_n_atoms','qm9_block','qm9_atom_type',\n",
    "                'qm9_xyz','mulliken','in_file','smile','distance','coulomb']\n",
    "\n",
    "rdkit_features = ['atom_type','atomic_number','aromatic','chirality',\n",
    "                  'degree','charge','n_hs','n_rads','hybridization',\n",
    "                  'edge_indices','edge_attr','rdmol_block','n_atoms',\n",
    "                  'xyz','distance','coulomb','adjacency','rdmol']\n",
    "\n",
    "rdkit_edge = ['edge_indices','edge_attr']\n",
    "\n",
    "qm9_features = ['A','B','C','mu','alpha','homo','lumo', 'gap','r2','zpve',\n",
    "                'U0','U','H','G','Cv','qm9_n_atoms','qm9_block','qm9_atom_type',\n",
    "                'qm9_xyz','mulliken','in_file','smile','distance','coulomb']\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['U0']}},\n",
    "                              'n': 10000, #non-random subset for testing\n",
    "                              'transforms': {'coulomb': [Pad((29,29)),Reshape((-1))],\n",
    "                                             'U0': [SqueezeN()]},\n",
    "                              'filter_on': ('n_atoms','>','10'), #filter out molecules with less than 10 atoms\n",
    "                              'use_pickle': False}}\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['aromatic','degree',\n",
    "                                                                   'charge','coulomb'],\n",
    "                                                             'embed': ['hybridization','chirality']},\n",
    "                                             'criterion_input': {'target': ['U0']}},\n",
    "                              'n': 10000, #non-random subset for testing\n",
    "                              'n_conformers': 10,\n",
    "                              'pad': 29,\n",
    "                              'pad_feats': ['mulliken','coulomb','aromatic','degree',\n",
    "                                            'charge','n_hs','n_rads','atomic_number',\n",
    "                                            'hybridization','chirality'],\n",
    "                              'as_tensor': True,\n",
    "                              'filter_on': ('n_atoms','>','10'), #filter out molecules with less than 10 atoms\n",
    "                              'use_pickle': False,\n",
    "                              'flatten': True}}\n",
    "\n",
    "model_params = {'in_channels': 29*29, \n",
    "                'hidden': 4096, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'\n",
    "               }\n",
    "\n",
    "model_params = {'in_channels': 29+29+29+29*29+29*16+29*16, \n",
    "                'hidden': 4096, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel',\n",
    "                'embed_params': [('hybridization',9,16,0,True),('chirality',5,16,0,True)]\n",
    "               }      \n",
    "\n",
    "metrics_params = {'report_interval': 1,\n",
    "                  'log_plot': False}\n",
    "\n",
    "metrics_params = {'report_interval': 1,\n",
    "                  'log_plot': False}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15),\n",
    "                 'subset': .2 #create random subset\n",
    "                 \n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 5,\n",
    "                'cooldown': 2}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "\n",
    "\n",
    "l = Learn([QM9], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          squeeze_y_pred=True, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example cosmosis/qchem QM9 dataset with filter, rdkit data augmentation, \n",
    "#multiple conformations, embeddings and custom model \n",
    "rdkit_features = ['atom_type','atomic_number','aromatic','chirality',\n",
    "                  'degree','charge','n_hs','n_rads','hybridization',\n",
    "                  'edge_indices','edge_attr','rdmol_block','n_atoms',\n",
    "                  'xyz','distance','coulomb','adjacency','rdmol']\n",
    "\n",
    "rdkit_edge = ['edge_indices','edge_attr']\n",
    "\n",
    "qm9_features = ['A','B','C','mu','alpha','homo','lumo', 'gap','r2','zpve',\n",
    "                'U0','U','H','G','Cv','qm9_n_atoms','qm9_block','qm9_atom_type',\n",
    "                'qm9_xyz','mulliken','in_file','smile','distance','coulomb']\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['aromatic','degree',\n",
    "                                                                   'charge','coulomb'],\n",
    "                                                             'embed': ['hybridization','chirality']},\n",
    "                                             'criterion_input': {'target': ['U0']}},\n",
    "                              'n': 10000, #non-random subset for testing\n",
    "                              'n_conformers': 10,\n",
    "                              'pad': 29,\n",
    "                              'pad_feats': ['mulliken','coulomb','aromatic','degree',\n",
    "                                            'charge','n_hs','n_rads','atomic_number',\n",
    "                                            'hybridization','chirality'],\n",
    "                              'as_tensor': True,\n",
    "                              'filter_on': ('n_atoms','>','10'), #filter out molecules with less than 10 atoms\n",
    "                              'use_pickle': False,\n",
    "                              'flatten': True}}\n",
    "\n",
    "\n",
    "model_params = {'in_channels': 29+29+29+29*29+29*16+29*16, \n",
    "                'hidden': 4096, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel',\n",
    "                'embed_params': [('hybridization',9,16,0,True),('chirality',5,16,0,True)]\n",
    "               }\n",
    "                \n",
    "metrics_params = {'report_interval': 1,\n",
    "                  'log_plot': False}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15),\n",
    "                 'subset': .2 #create random subset\n",
    "                }\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 5,\n",
    "                'cooldown': 2}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM9], FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with Data object output with\n",
    "#custom transforms and sklearn metrics and custom PyG model\n",
    "\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        #Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "model_params = {'in_channels': 11, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 1,\n",
    "                'depth': 1,\n",
    "                'convolution': 'NetConv',\n",
    "                'pool': 'MeanAggregation',\n",
    "                'dropout': .1,\n",
    "                'softmax': None,\n",
    "                'activation': 'relu',\n",
    "                'edge_features': 4,\n",
    "               }\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': T.Compose([IndexY(0), \n",
    "                                                                   ])}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], GraphNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=True, batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example graph variational autoencoder without adversarial regulation and GCNConv encoder\n",
    "\n",
    "model_params = {'in_channels': 11, \n",
    "                'hidden': 32, \n",
    "                'out_channels': 32,\n",
    "                'depth': 2,\n",
    "                'softmax': None,\n",
    "                'pool': None,\n",
    "                'convolution': 'GCNConv'}\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': None}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'adversarial': False,\n",
    "               'disc_params': {'in_channels': 32, 'hidden': 64, \n",
    "                                'out_channels': 32, 'softmax': None}}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15),\n",
    "                 'subset': False}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], GraphNetVariationalEncoder, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=EncoderLoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=False, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example graph variational autoencoder with adversarial regulation and GCNConv encoder\n",
    "\n",
    "model_params = {'in_channels': 11, \n",
    "                'hidden': 32, \n",
    "                'out_channels': 32,\n",
    "                'depth': 2,\n",
    "                'softmax': None,\n",
    "                'pool': None,\n",
    "                'convolution': 'GCNConv'}\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': None}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'adversarial': True,\n",
    "               'disc_params': {'in_channels': 32, 'hidden': 64, \n",
    "                                'out_channels': 32, 'softmax': None}}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15),\n",
    "                 'subset': False}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], GraphNetVariationalEncoder, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=EncoderLoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=False, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with Data object output with\n",
    "#custom transforms and sklearn metrics and custom PyG model\n",
    "\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        # Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "model_params = {'in_channels': 11, \n",
    "                'hidden': 256, \n",
    "                'out_channels': 1,\n",
    "                'depth': 2,\n",
    "                'convolution': 'SAGEConv',\n",
    "                'pool': 'MeanAggregation',\n",
    "                'dropout': .1,\n",
    "                'softmax': None,\n",
    "                'activation': 'relu',\n",
    "               }\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': T.Compose([IndexY(0), \n",
    "                                                                   ])}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], GraphNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=True, batch_size=256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with Data object output with\n",
    "#custom transforms and sklearn metrics and PyG model\n",
    "\n",
    "class IndexY(T.BaseTransform):\n",
    "    def __init__(self, i):\n",
    "        self.i = i\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        # Shallow-copy the data so that we prevent in-place data modification.\n",
    "        return self.forward(copy.copy(data))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        y = data.y[:,self.i]\n",
    "        data.y = y\n",
    "        return data\n",
    "\n",
    "model_params = {'model_name': 'GraphSAGE',\n",
    "                'softmax': None,\n",
    "                'pool': 'MeanAggregation',\n",
    "                'ffnet': True,\n",
    "                'in_channels': 256, #ffnet params\n",
    "                'hidden': 256, \n",
    "                'out_channels': 1, \n",
    "                'pyg_params': {'in_channels': 11, #GraphSAGE params\n",
    "                               'hidden_channels': 256,\n",
    "                               'num_layers': 2,\n",
    "                               'out_channels': 256,\n",
    "                               'dropout': .1,\n",
    "                               'norm': 'BatchNorm'}}\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {},\n",
    "                              'pg_params': {'root': './data/',\n",
    "                                            'transform': T.Compose([IndexY(0)])}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], PygModel, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, DataLoader=DataLoader,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          squeeze_y_pred=True, batch_size=256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis/qchem PyG dataset wrapper with custum transform with\n",
    "#dictionary output and custom cosmosis model\n",
    "\n",
    "model_params = {'in_channels': 319, \n",
    "                'hidden': 512, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'dataset': 'QM9',\n",
    "                              'transforms': {'y': [Index(0)],\n",
    "                                             'x': [Pad((29,11)), Flatten()]},\n",
    "                              'input_dict': {'model_input': {'X': ['x']},\n",
    "                                             'criterion_input': {'target': ['y']}},\n",
    "                              'pg_params': {'root': './data/'}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': False}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7, .15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "l = Learn([PGDS], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=MSELoss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using cosmosis/qchem QM7 dataset and custom cosmosis model\n",
    "model_params = {'in_channels': 23*23, \n",
    "                'hidden': 2048, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['ae']}},\n",
    "                              'in_file': './data/qm7/qm7.mat',\n",
    "                              'transforms': {'coulomb': [Flatten()]}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM7], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using the cosmosis/qchem QM7b dataset and custom cosmosis model\n",
    "model_params = {'in_channels': 23*23, \n",
    "                'hidden': 2048, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['E']}},\n",
    "                              'in_file': './data/qm7b/qm7b.mat',\n",
    "                              'transforms': {'coulomb': [Flatten()]}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM7b], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params, \n",
    "          batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['E']}},\n",
    "                              'in_file': './data/qm7b/qm7b.mat',\n",
    "                              'transforms': {'coulomb': [Flatten()]}}}\n",
    "\n",
    "qm7b = QM7b(**ds_params['train_params'])\n",
    "qm7b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm7b[1]['model_input']['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example exploring cosmosis/qchem QM7X dataset\n",
    "\n",
    "features = ['DIP','HLgap','atC6','atNUM','atPOL','atXYZ','eAT','hDIP',\n",
    "            'eC','eDFTB+MBD','eEE','eH','eKIN','eKSE','eL','eMBD','eNE', \n",
    "            'eNN','ePBE0','ePBE0+MBD','eTS','eX','eXC','eXX','hCHG', \n",
    "            'hRAT','hVDIP','hVOL','mC6','mPOL','mTPOL','pbe0FOR', \n",
    "            'sMIT','sRMSD','totFOR','vDIP','vEQ','vIQ','vTQ','vdwFOR','vdwR',\n",
    "            'coulomb'] #(1110,) with pad=23\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['atNUM']},\n",
    "                                             'criterion_input': {'target': ['eAT']}},\n",
    "                              'transforms': {},\n",
    "                              'n': 1000, #non-random subset for testing\n",
    "                              'selector': ['opt']}}\n",
    "\n",
    "qm7x = QM7X(**ds_params['train_params'])\n",
    "\n",
    "l, m = 0, 0\n",
    "for i in qm7x.ds_idx:\n",
    "    s = qm7x[i]['model_input']['X'].shape[0]\n",
    "    if s > l:\n",
    "        l = s\n",
    "        m = i\n",
    "print('longest molecule length: ', l, ' index: ', m)\n",
    "print(qm7x[m]['model_input']['X'].shape) \n",
    "qm7x[m]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using the cosmosis/qchem QM7X dataset with filter and custom cosmosis model\n",
    "model_params = {'in_channels': 23*23,\n",
    "                'hidden': 2048, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "features = ['DIP','HLgap','atC6','atNUM','atPOL','atXYZ','hDIP','eAT',\n",
    "            'eC','eDFTB+MBD','eEE','eH','eKIN','eKSE','eL','eMBD','eNE', \n",
    "            'eNN','ePBE0','ePBE0+MBD','eTS','eX','eXC','eXX','hCHG', \n",
    "            'hRAT','hVDIP','hVOL','mC6','mPOL','mTPOL','pbe0FOR', \n",
    "            'sMIT','sRMSD','totFOR','vDIP','vEQ','vIQ','vTQ','vdwFOR','vdwR',\n",
    "            'coulomb','distance']\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['eAT']}},\n",
    "                              'transforms': {'coulomb': [Pad((23,23)), Flatten()]},\n",
    "                              'selector': ['opt'],\n",
    "                              'n': 1000, #non-random subset for testing\n",
    "                             }}\n",
    "\n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15),\n",
    "                 #'subset': .2 #create random subset\n",
    "                } \n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([QM7X], FFNet, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example using cosmosis/qchem ANI1x dataset with filter and custom cosmosis model\n",
    "\n",
    "model_params = {'in_channels': 63*63, #length of the longest molecule in the dataset\n",
    "                'hidden': 2000, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'\n",
    "               }\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['coulomb']},\n",
    "                                             'criterion_input': {'target': ['wb97x_dz.energy']}},\n",
    "                              'transforms': {'coulomb': [Pad((63,63)), Flatten()]},\n",
    "                              'criterion': ['wb97x_dz.energy'],\n",
    "                              'conformation': 'max',\n",
    "                              'in_file': './data/ani1x/ani1x-release.h5'}}\n",
    "\n",
    "metrics_params = {'report_interval': 20}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1,\n",
    "                'min_lr': .005}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "l = Learn([ANI1x], FFNet, Selector, Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=L1Loss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
